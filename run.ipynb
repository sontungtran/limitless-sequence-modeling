{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d0d1ea6-3c87-4473-8153-e68bb0d4a77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model import *\n",
    "from src.lookup import *\n",
    "from src.summarize import *\n",
    "from src.checkpoint_util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c1f76ea-a109-446d-8add-cfe64a8ed8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import opendatasets as od\n",
    "# import transformers\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "import random \n",
    "import os\n",
    "import numpy as np\n",
    "# import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import roc_curve\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from transformers import RobertaTokenizer\n",
    "\n",
    "\n",
    "seed = 1293182\n",
    "random.seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48be42e6-e482-4944-ba59-236d5cd1cdcd",
   "metadata": {
    "id": "o1aTFCrKsL3L"
   },
   "outputs": [],
   "source": [
    "fake_df = pd.read_csv('data/fake-and-real-news-dataset/Fake.csv')\n",
    "true_df = pd.read_csv('data/fake-and-real-news-dataset/True.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b6906c2-7247-4753-8288-883948bd34b5",
   "metadata": {
    "id": "HuNV4fOgscPI"
   },
   "outputs": [],
   "source": [
    "fake_df['news'] = fake_df['text']\n",
    "fake_df['news'] = fake_df['title'] + '\\n' + fake_df['news']\n",
    "fake_df['label'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d9d64cc-bf0d-40a2-8e7c-24d32626897d",
   "metadata": {
    "id": "g9MUETVwtmw8"
   },
   "outputs": [],
   "source": [
    "true_df['news'] = true_df['text']\n",
    "true_df['news'] = true_df['title'] + '\\n' + true_df['news']\n",
    "true_df['label'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97ff546d-ee08-41bc-b4c8-560a1a35f8f3",
   "metadata": {
    "id": "iVICLbMeuapJ"
   },
   "outputs": [],
   "source": [
    "all_data = pd.concat([true_df, fake_df])[['news', 'label']].sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a37c25ad-2f72-43ed-9b5c-5ed7d97256fc",
   "metadata": {
    "id": "Pbd3PKGL0XrG"
   },
   "outputs": [],
   "source": [
    "news_lens = {}\n",
    "\n",
    "for news in all_data.news.values:\n",
    "  news_len = len(news.split())\n",
    "  if news_len in news_lens:\n",
    "    news_lens[news_len] += 1\n",
    "  else:\n",
    "    news_lens[news_len] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95fdb5e2-3679-4971-9e98-29b138259183",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "id": "e7oxS2Ok0vcm",
    "outputId": "205404fa-6778-46b1-e87b-9d80c5ba175b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 1609 artists>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(list(news_lens.keys()), list(news_lens.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "910ad5a9-3f38-4d4e-bca9-afb09223be92",
   "metadata": {
    "id": "8m8KzLaF2mZ2"
   },
   "outputs": [],
   "source": [
    "config  =  {'model':\"roberta-base\",\n",
    "            'maxlen' :512,\n",
    "            'train_batch_size':1,\n",
    "            'valid_batch_size':1,\n",
    "            'epochs':1,\n",
    "#             'learning_rates':[0.25e-4, 0.25e-4, 0.25e-4, 0.25e-4, 0.25e-5], #Custom lr proven to work well in my previous tasks\n",
    "            'learning_rates':[0.5e-5, 0.25e-4, 0.25e-4, 0.25e-4, 0.25e-5],\n",
    "            'max_grad_norm':10,\n",
    "            'device':'cuda' if torch.cuda.is_available() else 'cpu'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1d80594-08bd-4e7a-abf5-054c511e7c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters for summarization\n",
    "N = 45\n",
    "n = 15 # Input tokens size\n",
    "m = 5 # Number of summaries in each window\n",
    "k = 1 # Number of lookups in each window\n",
    "p = 1/13\n",
    "\n",
    "assert m > k, \"Should be m > k\"\n",
    "assert n < N, \"Should be n < N\"\n",
    "assert k < (N-1)/n - 1, f\"Should be k < (N-1)/n - 1, but {k} < {(N-1)/n - 1}\"\n",
    "assert 0 <= p and p <= ((N-1)-n*(1+k))/(N*(m-k)), f\"0 <= {p} <= {((N-1)-n*(1+k))/(N*(m-k))} is not satisfied\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3cd86f3-fd7f-4ec8-ab52-3b7552fcf9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "use_finetuned = False\n",
    "model_config = RobertaConfig(\n",
    "    _name_or_path=\"roberta-base\",\n",
    "    architectures=[\"RobertaForMaskedLM\"],\n",
    "    bos_token_id= 0,\n",
    "    classifier_dropout=None,\n",
    "    eos_token_id=2,\n",
    "    hidden_act=\"gelu\",\n",
    "    hidden_dropout_prob=0.1,\n",
    "    hidden_size=768,\n",
    "    initializer_range=0.02,\n",
    "    intermediate_size=3072,\n",
    "    layer_norm_eps=1e-05,\n",
    "    max_position_embeddings=514,\n",
    "    model_type=\"roberta\",\n",
    "    num_attention_heads=12,\n",
    "    num_hidden_layers=12,\n",
    "    pad_token_id=1,\n",
    "    position_embedding_type=\"absolute\",\n",
    "    transformers_version=\"4.15.0\",\n",
    "    type_vocab_size=1,\n",
    "    use_cache=True,\n",
    "    vocab_size=50265,\n",
    "    summarize_layers = [11],\n",
    "    shrink_percentage = p,\n",
    "    num_labels=2\n",
    ")\n",
    "if use_finetuned:\n",
    "    tokenizer = RobertaTokenizer.from_pretrained(\"models\")\n",
    "else:\n",
    "    tokenizer = RobertaTokenizer.from_pretrained(config['model'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69adaaec-54d7-4eae-986c-39abfd6bbd76",
   "metadata": {
    "id": "rshMjj79rqzF"
   },
   "source": [
    "### 2.2 Set up a train, validation, and test set\n",
    "\n",
    "I am opting for using 20% of the original dataset as the test set to make sure that the model generalizes well. The rest will be the train-val set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f00f8a8c-6756-411d-805c-c7702e698e81",
   "metadata": {
    "id": "oZXnuMzzvtSS"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class NewsClsDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, maxlen=512):\n",
    "        self.data = df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.maxlen = maxlen\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        text = self.data.news.values[index]\n",
    "        labels = self.data.label.values[index]\n",
    "        \n",
    "        encoded = self.tokenizer(text.split(),\n",
    "                                is_split_into_words=True,)\n",
    "#                                 padding='max_length',\n",
    "#                                 truncation=True,\n",
    "#                                 max_length=self.maxlen)\n",
    "        \n",
    "        input_ids = encoded['input_ids'][1:]\n",
    "        masks = encoded['attention_mask'][1:]        \n",
    "            \n",
    "        item = {'input_ids': torch.tensor(input_ids),\n",
    "                'attention_masks': torch.tensor(masks),\n",
    "                'labels': torch.tensor(labels)}\n",
    "\n",
    "        return item\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9788d0e-6f3b-4024-80ee-803b87c684b4",
   "metadata": {
    "id": "TINPVtqcuSh2"
   },
   "outputs": [],
   "source": [
    "train_val_df, test_df = train_test_split(all_data, test_size=0.2, random_state=42)\n",
    "train_df, val_df = train_test_split(train_val_df, test_size=0.1, random_state=42)\n",
    "\n",
    "train_dataset = NewsClsDataset(train_df, tokenizer, config['maxlen'])\n",
    "val_dataset =  NewsClsDataset(val_df, tokenizer, config['maxlen'])\n",
    "test_dataset = NewsClsDataset(test_df, tokenizer, config['maxlen'])\n",
    "\n",
    "# TRAIN DATASET AND VALID DATASET\n",
    "train_params = {'batch_size': config['train_batch_size'],\n",
    "                'shuffle': True,\n",
    "                'num_workers': 2,\n",
    "                'pin_memory':True\n",
    "                }\n",
    "\n",
    "test_params = {'batch_size': config['valid_batch_size'],\n",
    "                'shuffle': False,\n",
    "                'num_workers': 2,\n",
    "                'pin_memory':True\n",
    "                }\n",
    "train_data = DataLoader(train_dataset, **train_params)\n",
    "val_data = DataLoader(val_dataset, **train_params)\n",
    "test_data = DataLoader(test_dataset, **test_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5d4701-55bc-472c-b5bf-87f71398ccaf",
   "metadata": {
    "id": "mNts9VrHryRe"
   },
   "source": [
    "#### Check for balanced label distribution before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd7a0ebc-7490-4fd6-9f9c-bbba8bb1c95f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of train_val: 0.47708669747758786\n",
      "Distribution of test: 0.4767260579064588\n"
     ]
    }
   ],
   "source": [
    "print(\"Distribution of train_val:\", sum(train_val_df.label)/len(train_val_df))\n",
    "print(\"Distribution of test:\", sum(test_df.label)/len(test_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209ebc3f-2c22-4923-9b1e-f52f8e263501",
   "metadata": {
    "id": "lcY8_JTir7r3"
   },
   "source": [
    "### 2.3 Create a dataset wrapper class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa8bac9b-9dea-4081-b574-8a27ee0af63c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can't find checkpoint: \"ckpt-test_run.json\", using downloaded pretrained model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.bias', 'lm_head.layer_norm.weight', 'roberta.pooler.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Learning rate = 1e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                 | 0/32326 [00:00<?, ?it/s]/home/tst008/.local/lib/python3.9/site-packages/transformers/modeling_utils.py:699: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_loss: 0.5833278620243072\n",
      "Acc: tensor(1., device='cuda:0')\n",
      "Length of current stats file: 0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                      | 2/32326 [00:22<89:33:16,  9.97s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1306 > 512). Running this sequence through the model will result in indexing errors\n",
      "  0%|                                     | 9/32326 [02:33<175:41:11, 19.57s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (540 > 512). Running this sequence through the model will result in indexing errors\n",
      "  0%|                                    | 10/32326 [02:44<150:08:02, 16.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_loss: 0.632700239623451\n",
      "Acc: tensor(0.7432, device='cuda:0')\n",
      "Length of current stats file: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                    | 20/32326 [06:39<224:46:16, 25.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_loss: 0.6795808264425999\n",
      "Acc: tensor(0.5898, device='cuda:0')\n",
      "Length of current stats file: 2\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                    | 30/32326 [17:55<617:16:06, 68.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_loss: 0.4532690116523839\n",
      "Acc: tensor(0.7427, device='cuda:0')\n",
      "Length of current stats file: 3\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                    | 40/32326 [21:15<171:53:04, 19.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_loss: 0.4643302996892941\n",
      "Acc: tensor(0.7534, device='cuda:0')\n",
      "Length of current stats file: 4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                    | 50/32326 [26:28<313:54:12, 35.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_loss: 0.51992806087924\n",
      "Acc: tensor(0.6945, device='cuda:0')\n",
      "Length of current stats file: 5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                    | 60/32326 [29:48<150:52:58, 16.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_loss: 0.5336239476397325\n",
      "Acc: tensor(0.6869, device='cuda:0')\n",
      "Length of current stats file: 6\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                    | 70/32326 [33:37<148:36:05, 16.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_loss: 0.5487584895288491\n",
      "Acc: tensor(0.6716, device='cuda:0')\n",
      "Length of current stats file: 7\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                    | 80/32326 [37:09<152:50:04, 17.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_loss: 0.556942673282296\n",
      "Acc: tensor(0.6636, device='cuda:0')\n",
      "Length of current stats file: 8\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                    | 90/32326 [39:27<137:37:32, 15.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_loss: 0.5391476134410118\n",
      "Acc: tensor(0.6816, device='cuda:0')\n",
      "Length of current stats file: 9\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                   | 100/32326 [42:30<113:41:31, 12.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_loss: 0.5050356712669104\n",
      "Acc: tensor(0.7040, device='cuda:0')\n",
      "Length of current stats file: 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                   | 110/32326 [45:36<111:05:20, 12.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_loss: 0.502774713171381\n",
      "Acc: tensor(0.7132, device='cuda:0')\n",
      "Length of current stats file: 11\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▏                                  | 120/32326 [49:15<198:09:48, 22.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_loss: 0.4950568873956935\n",
      "Acc: tensor(0.7242, device='cuda:0')\n",
      "Length of current stats file: 12\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▏                                  | 130/32326 [53:53<247:25:05, 27.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_loss: 0.47773607927795403\n",
      "Acc: tensor(0.7378, device='cuda:0')\n",
      "Length of current stats file: 13\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▏                                  | 140/32326 [58:48<344:57:34, 38.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_loss: 0.44741483985085223\n",
      "Acc: tensor(0.7564, device='cuda:0')\n",
      "Length of current stats file: 14\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▏                                | 150/32326 [1:02:18<234:29:58, 26.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_loss: 0.4211548424884024\n",
      "Acc: tensor(0.7714, device='cuda:0')\n",
      "Length of current stats file: 15\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▏                                | 160/32326 [1:06:41<156:16:32, 17.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_loss: 0.39533801206255575\n",
      "Acc: tensor(0.7856, device='cuda:0')\n",
      "Length of current stats file: 16\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏                                | 170/32326 [1:10:35<231:13:54, 25.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_loss: 0.38245627099247853\n",
      "Acc: tensor(0.7950, device='cuda:0')\n",
      "Length of current stats file: 17\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏                                | 180/32326 [1:13:51<175:31:18, 19.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_loss: 0.37592672439320296\n",
      "Acc: tensor(0.7995, device='cuda:0')\n",
      "Length of current stats file: 18\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏                                | 190/32326 [1:18:23<278:54:27, 31.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_loss: 0.365211042453461\n",
      "Acc: tensor(0.8073, device='cuda:0')\n",
      "Length of current stats file: 19\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏                                | 200/32326 [1:22:29<207:31:55, 23.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_loss: 0.3612876267904618\n",
      "Acc: tensor(0.8094, device='cuda:0')\n",
      "Length of current stats file: 20\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏                                | 210/32326 [1:25:39<105:35:36, 11.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_loss: 0.34890657535979236\n",
      "Acc: tensor(0.8164, device='cuda:0')\n",
      "Length of current stats file: 21\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏                                | 220/32326 [1:30:24<210:42:18, 23.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_loss: 0.33799237141703264\n",
      "Acc: tensor(0.8236, device='cuda:0')\n",
      "Length of current stats file: 22\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏                                | 230/32326 [1:33:32<117:50:37, 13.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_loss: 0.3319111547400034\n",
      "Acc: tensor(0.8272, device='cuda:0')\n",
      "Length of current stats file: 23\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏                                | 240/32326 [1:36:53<187:19:26, 21.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_loss: 0.3199207356713334\n",
      "Acc: tensor(0.8336, device='cuda:0')\n",
      "Length of current stats file: 24\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▎                                | 250/32326 [1:41:55<418:40:59, 46.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_loss: 0.3228170350863757\n",
      "Acc: tensor(0.8353, device='cuda:0')\n",
      "Length of current stats file: 25\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▎                                | 260/32326 [1:44:57<181:48:05, 20.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_loss: 0.3277778703368876\n",
      "Acc: tensor(0.8342, device='cuda:0')\n",
      "Length of current stats file: 26\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▎                                | 270/32326 [1:48:01<170:23:58, 19.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_loss: 0.32164659377059707\n",
      "Acc: tensor(0.8376, device='cuda:0')\n",
      "Length of current stats file: 27\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▎                                | 280/32326 [1:51:21<110:42:50, 12.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_loss: 0.31503887485888893\n",
      "Acc: tensor(0.8415, device='cuda:0')\n",
      "Length of current stats file: 28\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▎                                | 290/32326 [1:55:20<161:43:30, 18.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_loss: 0.32013807149006707\n",
      "Acc: tensor(0.8393, device='cuda:0')\n",
      "Length of current stats file: 29\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▎                                | 300/32326 [1:58:18<179:53:21, 20.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_loss: 0.3135947890054157\n",
      "Acc: tensor(0.8432, device='cuda:0')\n",
      "Length of current stats file: 30\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▎                                | 310/32326 [2:01:26<192:05:25, 21.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_loss: 0.3050434699841196\n",
      "Acc: tensor(0.8475, device='cuda:0')\n",
      "Length of current stats file: 31\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▎                                | 320/32326 [2:04:18<119:02:24, 13.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_loss: 0.2976613443377975\n",
      "Acc: tensor(0.8513, device='cuda:0')\n",
      "Length of current stats file: 32\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▎                                | 330/32326 [2:07:35<134:47:10, 15.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_loss: 0.28956321525917916\n",
      "Acc: tensor(0.8553, device='cuda:0')\n",
      "Length of current stats file: 33\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▎                                | 340/32326 [2:10:07<147:28:54, 16.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_loss: 0.28783048738489425\n",
      "Acc: tensor(0.8574, device='cuda:0')\n",
      "Length of current stats file: 34\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▎                                | 350/32326 [2:13:26<126:00:59, 14.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_loss: 0.28140781026409684\n",
      "Acc: tensor(0.8608, device='cuda:0')\n",
      "Length of current stats file: 35\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▎                                | 360/32326 [2:16:11<143:48:23, 16.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_loss: 0.2756917376247155\n",
      "Acc: tensor(0.8636, device='cuda:0')\n",
      "Length of current stats file: 36\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▍                                | 370/32326 [2:19:05<180:42:00, 20.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_loss: 0.269767043963895\n",
      "Acc: tensor(0.8667, device='cuda:0')\n",
      "Length of current stats file: 37\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▍                                 | 380/32326 [2:21:33<87:07:47,  9.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_loss: 0.26440321766868585\n",
      "Acc: tensor(0.8694, device='cuda:0')\n",
      "Length of current stats file: 38\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▍                                | 390/32326 [2:24:09<158:46:46, 17.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_loss: 0.26016691441021433\n",
      "Acc: tensor(0.8715, device='cuda:0')\n",
      "Length of current stats file: 39\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▍                                | 400/32326 [2:28:05<175:04:16, 19.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_loss: 0.2531548302162783\n",
      "Acc: tensor(0.8750, device='cuda:0')\n",
      "Length of current stats file: 40\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▍                                 | 410/32326 [2:30:45<91:38:00, 10.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_loss: 0.2484686691202423\n",
      "Acc: tensor(0.8774, device='cuda:0')\n",
      "Length of current stats file: 41\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▍                                | 420/32326 [2:34:29<262:14:03, 29.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_loss: 0.2426541232248069\n",
      "Acc: tensor(0.8802, device='cuda:0')\n",
      "Length of current stats file: 42\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▍                                | 430/32326 [2:36:57<128:13:04, 14.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_loss: 0.23857255288782073\n",
      "Acc: tensor(0.8823, device='cuda:0')\n",
      "Length of current stats file: 43\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▍                                | 440/32326 [2:40:58<242:54:41, 27.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_loss: 0.2321434154655509\n",
      "Acc: tensor(0.8854, device='cuda:0')\n",
      "Length of current stats file: 44\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▍                                | 450/32326 [2:44:26<191:12:04, 21.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_loss: 0.22763078270523202\n",
      "Acc: tensor(0.8876, device='cuda:0')\n",
      "Length of current stats file: 45\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▍                                | 460/32326 [2:48:29<218:51:38, 24.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_loss: 0.22192563050904868\n",
      "Acc: tensor(0.8905, device='cuda:0')\n",
      "Length of current stats file: 46\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▍                                | 470/32326 [2:52:46<262:34:17, 29.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_loss: 0.21671571432564146\n",
      "Acc: tensor(0.8930, device='cuda:0')\n",
      "Length of current stats file: 47\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▍                                | 480/32326 [2:57:09<190:04:34, 21.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_loss: 0.21161467962577518\n",
      "Acc: tensor(0.8955, device='cuda:0')\n",
      "Length of current stats file: 48\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▌                                 | 490/32326 [2:59:20<97:12:01, 10.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_loss: 0.20858485498828683\n",
      "Acc: tensor(0.8970, device='cuda:0')\n",
      "Length of current stats file: 49\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▌                                | 500/32326 [3:02:38<182:41:15, 20.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_loss: 0.2045119055467553\n",
      "Acc: tensor(0.8991, device='cuda:0')\n",
      "Length of current stats file: 50\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▌                                | 510/32326 [3:05:47<113:33:52, 12.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_loss: 0.20083629574571696\n",
      "Acc: tensor(0.9009, device='cuda:0')\n",
      "Length of current stats file: 51\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▌                                | 520/32326 [3:10:08<298:28:06, 33.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_loss: 0.19653605524781687\n",
      "Acc: tensor(0.9030, device='cuda:0')\n",
      "Length of current stats file: 52\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▌                                | 530/32326 [3:16:53<284:36:41, 32.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_loss: 0.19116357498882783\n",
      "Acc: tensor(0.9058, device='cuda:0')\n",
      "Length of current stats file: 53\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▌                                | 540/32326 [3:20:15<213:43:14, 24.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_loss: 0.18720899995231743\n",
      "Acc: tensor(0.9077, device='cuda:0')\n",
      "Length of current stats file: 54\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▌                                 | 550/32326 [3:22:31<70:25:21,  7.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_loss: 0.18544557987069088\n",
      "Acc: tensor(0.9086, device='cuda:0')\n",
      "Length of current stats file: 55\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▌                                | 560/32326 [3:25:24<177:53:28, 20.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_loss: 0.1827116265816542\n",
      "Acc: tensor(0.9099, device='cuda:0')\n",
      "Length of current stats file: 56\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▌                                 | 570/32326 [3:27:27<83:26:28,  9.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_loss: 0.18075782273333452\n",
      "Acc: tensor(0.9109, device='cuda:0')\n",
      "Length of current stats file: 57\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▌                                | 580/32326 [3:31:01<223:00:22, 25.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_loss: 0.1779081411301333\n",
      "Acc: tensor(0.9123, device='cuda:0')\n",
      "Length of current stats file: 58\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▌                                | 590/32326 [3:35:35<396:29:00, 44.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_loss: 0.17417566877354573\n",
      "Acc: tensor(0.9141, device='cuda:0')\n",
      "Length of current stats file: 59\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▌                                | 600/32326 [3:39:04<152:13:27, 17.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_loss: 0.17142022379750782\n",
      "Acc: tensor(0.9155, device='cuda:0')\n",
      "Length of current stats file: 60\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▌                                | 610/32326 [3:42:18<163:43:42, 18.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_loss: 0.16858531114704126\n",
      "Acc: tensor(0.9169, device='cuda:0')\n",
      "Length of current stats file: 61\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▋                                | 620/32326 [3:48:12<282:29:12, 32.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_loss: 0.16459063827330625\n",
      "Acc: tensor(0.9189, device='cuda:0')\n",
      "Length of current stats file: 62\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▋                                | 630/32326 [3:53:42<296:21:10, 33.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_loss: 0.16118778143715226\n",
      "Acc: tensor(0.9205, device='cuda:0')\n",
      "Length of current stats file: 63\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▋                                | 640/32326 [3:57:29<200:15:33, 22.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_loss: 0.1586485751594023\n",
      "Acc: tensor(0.9218, device='cuda:0')\n",
      "Length of current stats file: 64\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▋                                | 650/32326 [4:00:08<129:31:36, 14.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_loss: 0.15641457705756262\n",
      "Acc: tensor(0.9229, device='cuda:0')\n",
      "Length of current stats file: 65\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▋                                | 660/32326 [4:04:09<211:03:15, 23.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_loss: 0.15403551064632154\n",
      "Acc: tensor(0.9241, device='cuda:0')\n",
      "Length of current stats file: 66\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▋                                | 670/32326 [4:07:30<113:31:50, 12.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_loss: 0.15200895394605532\n",
      "Acc: tensor(0.9251, device='cuda:0')\n",
      "Length of current stats file: 67\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▋                                | 680/32326 [4:11:23<185:10:16, 21.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_loss: 0.14960605025394352\n",
      "Acc: tensor(0.9263, device='cuda:0')\n",
      "Length of current stats file: 68\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▋                                | 690/32326 [4:15:46<177:06:20, 20.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_loss: 0.14683930461539696\n",
      "Acc: tensor(0.9276, device='cuda:0')\n",
      "Length of current stats file: 69\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▋                                | 700/32326 [4:19:14<136:03:40, 15.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_loss: 0.14501637277077167\n",
      "Acc: tensor(0.9285, device='cuda:0')\n",
      "Length of current stats file: 70\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▋                                | 710/32326 [4:23:48<358:18:39, 40.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_loss: 0.14256848259990185\n",
      "Acc: tensor(0.9297, device='cuda:0')\n",
      "Length of current stats file: 71\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▋                                | 720/32326 [4:26:54<163:16:24, 18.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_loss: 0.1408263649502721\n",
      "Acc: tensor(0.9306, device='cuda:0')\n",
      "Length of current stats file: 72\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▋                                | 730/32326 [4:29:43<158:09:45, 18.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_loss: 0.1393062782352885\n",
      "Acc: tensor(0.9313, device='cuda:0')\n",
      "Length of current stats file: 73\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▊                                | 740/32326 [4:32:30<190:51:55, 21.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_loss: 0.13773052355583645\n",
      "Acc: tensor(0.9321, device='cuda:0')\n",
      "Length of current stats file: 74\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▊                                | 742/32326 [4:33:51<194:16:45, 22.14s/it]\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "max_tokens = 32\n",
    "model_name = f\"test_run\"\n",
    "model_dir = \"models\"\n",
    "\n",
    "# We warmed up with 128 indices before inserting tokens into embedding layer\n",
    "last_epoch, last_idx, ckpt_info, model, tokenizer, optimizer = load_checkpoint(model_dir, model_name, config, model_config)\n",
    "# print(ckpt_info)\n",
    "# raise\n",
    "if last_epoch == 0:\n",
    "    last_epoch = 1\n",
    "    nb_tr_steps = 0\n",
    "    nb_tr_examples = 0\n",
    "    tr_losses = 0\n",
    "    tr_accuracies = 0\n",
    "else:\n",
    "    nb_tr_steps = ckpt_info[\"info\"][-1][\"Num Tr Steps\"]\n",
    "    nb_tr_examples = ckpt_info[\"info\"][-1][\"Num Tr Examples\"]\n",
    "    tr_losses = ckpt_info[\"info\"][-1][\"Training Loss\"] * nb_tr_steps\n",
    "    tr_accuracies = ckpt_info[\"info\"][-1][\"Training Acc\"] * nb_tr_examples\n",
    "    for i in range(len(ckpt_info[\"info\"])):\n",
    "        epoch = ckpt_info[\"info\"][i][\"epoch\"]\n",
    "        idx = ckpt_info[\"info\"][i][\"idx\"]\n",
    "        train_loss, val_loss = ckpt_info[\"info\"][i][\"Training Loss\"], ckpt_info[\"info\"][i][\"Valid. Loss\"]\n",
    "        train_acc, val_acc = ckpt_info[\"info\"][i][\"Training Acc\"], ckpt_info[\"info\"][i][\"Valid. Acc\"]\n",
    "        train_time, val_time = ckpt_info[\"info\"][i][\"Training Time\"], ckpt_info[\"info\"][i][\"Valid. Time\"]\n",
    "        other_info = ckpt_info[\"info\"][i][\"Other\"]\n",
    "        print(f\"Epoch: {epoch}, index: {idx}, Learning rate = {config['learning_rates'][epoch]}\")\n",
    "        print(f\"Training loss epoch: {train_loss}\")\n",
    "        print(f\"Training accuracy epoch: {train_acc}, elapsed: {train_time}\")\n",
    "        print(f\"Val loss epoch: {val_loss}\")\n",
    "        print(f\"Val accuracy epoch: {val_acc}, elapsed: {val_time}\")\n",
    "        print(f\"Other: {other_info}\")\n",
    "        print()\n",
    "    \n",
    "for epoch in range(last_epoch, config['epochs']+1):\n",
    "    config['learning_rates'][epoch] = 0.1e-5\n",
    "    print(f\"Epoch: {epoch}, Learning rate = {config['learning_rates'][epoch]}\")\n",
    "    for g in optimizer.param_groups: \n",
    "        g['lr'] = config['learning_rates'][epoch]\n",
    "    lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    # Training\n",
    "    train_time = 0\n",
    "    \n",
    "    model.train()\n",
    "    for idx, batch in enumerate(tqdm(train_data)):\n",
    "        if idx <= last_idx:            \n",
    "            continue\n",
    "        \n",
    "#         print(f'batch[\"input_ids\"]: {batch[\"input_ids\"].shape}')\n",
    "#         raise\n",
    "#         if idx > 10:\n",
    "#             break\n",
    "        start_time = time.time()\n",
    "        # Use 30 max last tokens, split into 3, feed first ten into next 10 and so on.\n",
    "        # Then train using the last 10.\n",
    "        summarized_tokens = None\n",
    "        length = batch[\"input_ids\"].shape[1]\n",
    "        lt = LookupTable(config, N, n, m, k, p)\n",
    "        for i in range(length // n): # Minus the BOS token\n",
    "#             if i != 2:\n",
    "#                 continue\n",
    "            \n",
    "            # Need to use batch size of 1 for now\n",
    "            assert batch[\"input_ids\"].shape[0] == 1, \"Batch size must be 1 for now\"\n",
    "            \n",
    "            ids = torch.zeros(1, 512)\n",
    "            mask = torch.zeros(1, 512)\n",
    "            end = min( n*(i+1), length )\n",
    "            length_input_tokens = end - n*i\n",
    "            \n",
    "            ids[0,0] = 0 # BOS token\n",
    "            ids[0,1:length_input_tokens+1] = batch['input_ids'][0, n*i : end].clone()\n",
    "            ids[0,length_input_tokens+1:] = 1 # Padding\n",
    "            mask[0,:length_input_tokens+1] = 1\n",
    "            mask[0,length_input_tokens+1:] = 0 # Masks the padding\n",
    "#             print(f\"Tokens: {n*i} : {end}\")\n",
    "#             print(f\"ids: {ids.shape}, mask: {mask.shape}\")\n",
    "#             raise\n",
    "            \n",
    "            ids = ids.to(config['device'], dtype = torch.long) #[C, seq_length]\n",
    "            mask = mask.to(config['device'], dtype = torch.long)\n",
    "            labels = batch['labels'].to(config['device'], dtype = torch.long)\n",
    "\n",
    "            (loss, tr_logits), summarized_tokens_list = model(input_ids=ids, \n",
    "                                    attention_mask=mask, \n",
    "                                    labels=labels,\n",
    "                                    return_dict=False,\n",
    "                                    summarized_tokens=summarized_tokens)\n",
    "            summarized_tokens = summarized_tokens_list[0].detach()\n",
    "#             print(summarized_tokens.shape)\n",
    "                \n",
    "            # Track three types of losses separately\n",
    "            tr_losses += loss.item()\n",
    "            nb_tr_steps += 1\n",
    "            nb_tr_examples += labels.size(0)\n",
    "                \n",
    "\n",
    "            # compute training accuracy\n",
    "            flattened_targets = labels.view(-1) # shape (batch_size * seq_len,)\n",
    "            flattened_predictions = torch.argmax(tr_logits, axis=1)\n",
    "\n",
    "            tr_accuracies += sum(flattened_predictions==flattened_targets)\n",
    "\n",
    "            # gradient clipping\n",
    "            torch.nn.utils.clip_grad_norm_(\n",
    "                parameters=model.parameters(), max_norm=config['max_grad_norm']\n",
    "            )\n",
    "\n",
    "            # backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Summary hierarchy\n",
    "            lt.add(summarized_tokens, model, optimizer, labels, i, length)\n",
    "            \n",
    "            # This part should be in the LookupTable as well\n",
    "            # nth\n",
    "            max_order = max(lt.summarized_tokens_hierarchy.keys())\n",
    "            max_order = max_order if len(lt.summarized_tokens_hierarchy[max_order][\"summary_tokens\"]) < 2 else max_order-1\n",
    "            if max_order <= 2:\n",
    "                l = []\n",
    "            else:\n",
    "                l = [lt.summarized_tokens_hierarchy[\n",
    "                    max_order\n",
    "                ][\"summary_tokens\"][0]]\n",
    "            l = []\n",
    "        \n",
    "            # 1 2nd\n",
    "            if max_order < 2 or len(lt.summarized_tokens_hierarchy[2][\"summary_tokens\"]) < 2:\n",
    "                pass\n",
    "            elif lt.summarized_tokens_hierarchy[2][\"summary_tokens\"][-1].shape[0] == 0:\n",
    "                l.append(lt.summarized_tokens_hierarchy[2][\"summary_tokens\"][-2])\n",
    "            else:\n",
    "                l.append(lt.summarized_tokens_hierarchy[2][\"summary_tokens\"][-1])\n",
    "            \n",
    "            # 3 1st\n",
    "            if lt.summarized_tokens_hierarchy[1][\"summary_tokens\"][-1].shape[0] == 0:\n",
    "                l.extend(lt.summarized_tokens_hierarchy[1][\"summary_tokens\"][-4:-1])\n",
    "            else:\n",
    "                l.extend(lt.summarized_tokens_hierarchy[1][\"summary_tokens\"][-3:])\n",
    "\n",
    "            summarized_tokens = torch.concat(l)\n",
    "        \n",
    "        train_time += time.time() - start_time\n",
    "        \n",
    "        if idx % 10 == 0: #TODO: Magic number\n",
    "            train_loss = tr_losses / nb_tr_steps\n",
    "            train_acc = tr_accuracies / nb_tr_examples\n",
    "#             print(tr_losses)\n",
    "            print(f\"Epoch_loss:\", train_loss)\n",
    "            print(\"Acc:\", train_acc)\n",
    "            train_time /= 5\n",
    "\n",
    "            save_checkpoint(model, tokenizer,\n",
    "                            model_dir, model_name, config, \n",
    "                            epoch, idx,\n",
    "                            train_loss, 0, train_acc, 0, train_time, 0,\n",
    "                            nb_tr_steps, nb_tr_examples,\n",
    "                            {})\n",
    "            train_time = 0\n",
    "            \n",
    "    break #One epoch is enough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e722dd5-39d0-43c4-bf91-d45a0920f923",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
